# 2c662221 RNN Expressive Capacity: Space Complexity and Rational Recurrence

## Content
The expressive capacity of Recurrent Neural Network (RNN) architectures can be categorized using space complexity and rational recurrence. Space complexity measures the memory capacity of an RNN, while rational recurrence evaluates if the recurrent function can be represented using weighted finite-state automata (WFAs). Through this framework, architectures like LSTMs and QRNNs can be differentiated. The LSTM, for instance, is shown not to be rational, separating it from the QRNN. Moreover, stacked layers and various pooling functions can expand the expressive capabilities of these architectures. While the extension to unsaturated RNNs remains theoretical, evidence from formal language training suggests they follow a similar hierarchal pattern.

## Metadata
- **Created**: 2024-10-27 19:22:12.394163
- **Tags**: #RNN, #Expressive capacity, #Space complexity, #Rational recurrence

## Links
<!-- Add links to related notes here -->

## References
<!-- Add references or sources here -->

